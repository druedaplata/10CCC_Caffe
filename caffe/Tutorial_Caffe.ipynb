{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Redes Neuronales Convolucionales\n",
    "\n",
    "##Clasificación de Imágenes con Caffe y Digits.\n",
    "\n",
    "Caffe: https://github.com/BVLC/caffe\n",
    "\n",
    "Digits: https://github.com/NVIDIA/DIGITS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Arquitectura de una Red Neuronal Convolucional\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/mylenet.png\">\n",
    "\n",
    "Las redes Convolucionales son muy similares a las redes Neuronales normales. Están compuestas de neuronas que tienen pesos (weights) y bias que les permiten aprender. Cada neurona recibe unas entradas, realiza un producto punto y opcionalmente sigue una no-linealidad.}\n",
    "\n",
    "* Son redes con una estructura de conectividad especializada.\n",
    "\n",
    "\n",
    "* Entrenamiento supervisado.\n",
    "\n",
    "\n",
    "* Típicamente, tienen los siguientes elementos.\n",
    "\n",
    "  * Convolutional Layer\n",
    "  * Non-linearity\n",
    "  * Pooling Layer\n",
    "  * Fully Connected\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Convolutional Layer\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/convolution.gif\" width=400px align=center>\n",
    "\n",
    "La capa convolucional consiste en un grupo de filtros.\n",
    "Estos filtros son pequeños campos receptivos que desplazamos por todo el ancho y largo de la imagen de entrada, produciendo un mapa de características. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conectividad Local\n",
    "\n",
    "<img src=\"imagenes/local_connected.png\" width=70%>\n",
    "\n",
    "La idea consiste en conectar cada neurona en la capa de convolución con una región pequeña en la imagen de entrada, pero conectada a todos los canales de color. <br>Esta región la llamaremos el **campo receptivo (F)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Disposición Espacial\n",
    "\n",
    "Consiste de 3 hiperparámetros que controlan la salida que obtenemos de la red convolucional.\n",
    "\n",
    "1. **Depth (Profundidad):** Controla el número de neuronas en la capa convolucional que se conectan a la misma región en la imagen de entrada. Nos referimos a un grupo de neuronas que están conectadas a la misma región como una **columna de profundidad**.\n",
    "\n",
    "2. **Stride:** Este parámetro especifica el \"paso\" que dará nuestro campo receptivo para ubicar una nueva columna de profundidad.\n",
    "\n",
    "3. **Zero-padding:** En ocasiones será conveniente definir los bordes de la entrada a la red en ceros, ya que esto nos permitirá controlar el tamaño de la salida en la red neuronal.\n",
    "\n",
    "La salida de la capa convolucional se calcula de la siguiente manera:\n",
    "\n",
    "\\begin{equation}\n",
    "  W_{output} = [(W_{input}- F + 2P)/S + 1] \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "  H_{output} = [(H_{input} - F + 2P)/S + 1 ]  \n",
    "\\end{equation}\n",
    "\n",
    "Por lo tanto, si tenemos la siguiente situación:\n",
    "\n",
    "\\begin{equation}\n",
    "  Input = 227_{width} * 227_{height} * 3_{rgb}\n",
    "\\end{equation}\n",
    "\n",
    "...y definimos los hiperparámetros:\n",
    "\n",
    "\\begin{align}\n",
    "  Field = 11\\\\\n",
    "  Depth = 96\\\\\n",
    "  Stride = 4\\\\\n",
    "  Zero-padding = 0\n",
    "\\end{align}\n",
    "\n",
    "La salida de esta capa tendrá las siguientes dimensiones:\n",
    "\n",
    "\\begin{equation}\n",
    "  Output = 55_{width} * 55_{height} * 96_{neurons}\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"imagenes/conv_out_1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pesos y bias compartidos\n",
    "\n",
    "Hasta el momento cada neurona en nuestra red convolucional tiene $1$ bias y $11$x$11$ pesos conectados al campo perceptivo. \n",
    "\n",
    "Puesto que las imágenes naturales tienen propiedades **estacionarias**, es decir que las características aprendidas en una parte de la imagen serán útiles en cualquier otra parte.\n",
    "\n",
    "Gracias a esto podemos usar el mismo bias y $11$x$11$ pesos en todas las neuronas de la primera capa para que busquen, por ejemplo, una linea vertical en toda la imagen. Y usaremos pesos diferentes en las demas capas de neuronas para buscar diferentes características.\n",
    "\n",
    "<img src=\"imagenes/conv_out_2.png\" >\n",
    "\n",
    "Despues del entrenamiento estos $96$ pesos de $11$x$11$ aprenderán a reconocer características simples de la imagen.\n",
    "\n",
    "<img src=\"imagenes/features_conv1.jpg\" width=250>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Non-linearity Layer\n",
    "\n",
    "Podemos definir la salida de una capa en la red neuronal como $\\bar o$ que sería el resultado\n",
    "de una función de activación $f()$ aplicada al producto entre la entrada\n",
    "\n",
    "$\\bar x=\\begin{bmatrix}x_1\\\\x_2\\\\.\\\\.\\\\x_3\\\\x_4\\end{bmatrix}$ y los pesos de la capa \n",
    "$W=\\begin{bmatrix}w_{00} & w_{01} & . & . & w_{0n} & b_0\\\\\n",
    "                  w_{10} & w_{11} & . & . & w_{1n} & b_1\\\\\n",
    "                  . & . & . & . & . & .\\\\\n",
    "                  w_{n0} & w_{n1} & . & . & w_{nn} & b_n\\\\\\end{bmatrix}$ produciendo $\\bar o = f(W\\bar x)$\n",
    "                  \n",
    "Lo que podemos observar en este caso es que si usamos activación **lineal**, entonces una red neuronal con 2 capas se describiría de la siguiente forma:\n",
    "\n",
    "$\\bar o_1 = W_1\\bar x$\n",
    "\n",
    "$\\bar o_2 = W_2\\bar o_1 = W_2W_1\\bar x$\n",
    "\n",
    "Esto significa que añadir mas capas hara el sistemas mas lento y complicado, pero no mas expresivo. Esto no se cumple cuando usamos una función de activación **no lineal**.\n",
    "\n",
    "<img src=\"imagenes/relu.png\" style=\"float: left\">\n",
    "<img src=\"imagenes/sigmoid2.png\" style=\"float: left\" width=300>\n",
    "<img src=\"imagenes/tanh2.png\" style=\"float: left\" width=300>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "##Pooling Layer\n",
    "\n",
    "La función de esta capa es reducir el tamaño de la representación entregada por la capa convolucional para disminuir la cantidad de parámetros y disminuir el tiempo de calculo en la red.\n",
    "\n",
    "\n",
    "<img src=\"imagenes/pooling.png\" width=50%>\n",
    "\n",
    "\n",
    "Al igual que la red convolucional, recibe hiperparámetros que controlan su funcionamiento, el campo receptivo $F$ y el paso $S$. Frecuentemente se usa un campo receptivo pequeño, dado que con un mayor tamaño se perdería la representación en las características de la red.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##Fully Connected Layer\n",
    "\n",
    "Finalmente, después de varias capas convolucionales, no linealidades y posiblemente pooling, el razonamiento de alto nivel es realizado por las capas fully connected. Estas toman todas las neuronas en la capa anterior (ya sea convolucional, pooling o fully connected) y las conecta con todas las neuronas que tiene. \n",
    "\n",
    "<img src=\"imagenes/fully_connected.gif\">\n",
    "\n",
    "La última capa fully connected en el caso de clasificación de imágenes tendrá un número de neuronas igual a la cantidad de clases que estamos clasificando.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Entrenar una CNN usando CAFFE\n",
    "\n",
    "1. Seleccionar un dataset.\n",
    "2. Crear una estructura de red.\n",
    "3. Definir los hiperparámetros que guiarán el entrenamiento.\n",
    "4. Entrenar la red y evaluar la precisión sobre un dataset de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##1. Seleccionar un dataset\n",
    "\n",
    "Para este ejercicio usamos el dataset **Cifar 10**, que contiene objetos y animales de 10 categorias. El dataset consiste de 60000 imágenes de de 32x32. Para este ejercicio usaremos 45000 imágenes para entrenamiento y 5000 en validación.\n",
    "\n",
    "<img src=\"imagenes/cifar_10.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###1.1 Convertir a formato LMDB\n",
    "\n",
    "* Un archivo con la ruta a todas las imagenes y la categoría a la que pertenecen.\n",
    "\n",
    "        imagen_001.jpg 0\n",
    "        imagen_002.jpg 1\n",
    "        imagen_003.jpg 1\n",
    "        imagen_004.jpg 2\n",
    "        imagen_005.jpg 2\n",
    "        imagen_006.jpg 0\n",
    "        imagen_007.jpg 3\n",
    "        imagen_008.jpg 4\n",
    "\n",
    "\n",
    "* Las imágenes deben tener el mismo tamaño.\n",
    "* Convertimos las imagenes en formato LMDB para mejorar el tiempo de acceso de CAFFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train lmdb...\n",
      "Creating val lmdb...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 18:26:35.286201  7757 convert_imageset.cpp:79] Shuffling data\n",
      "I0724 18:26:35.444700  7757 convert_imageset.cpp:82] A total of 45000 images.\n",
      "I0724 18:26:35.444989  7757 db.cpp:34] Opened lmdb /home/sandiego/Programas/datasets/cifar10/cifar_train_lmdb\n",
      "E0724 18:26:35.718617  7757 convert_imageset.cpp:143] Processed 1000 files.\n",
      "E0724 18:26:36.007438  7757 convert_imageset.cpp:143] Processed 2000 files.\n",
      "E0724 18:26:36.285279  7757 convert_imageset.cpp:143] Processed 3000 files.\n",
      "E0724 18:26:36.574103  7757 convert_imageset.cpp:143] Processed 4000 files.\n",
      "E0724 18:26:36.874199  7757 convert_imageset.cpp:143] Processed 5000 files.\n",
      "E0724 18:26:37.174136  7757 convert_imageset.cpp:143] Processed 6000 files.\n",
      "E0724 18:26:37.463117  7757 convert_imageset.cpp:143] Processed 7000 files.\n",
      "E0724 18:26:37.763088  7757 convert_imageset.cpp:143] Processed 8000 files.\n",
      "E0724 18:26:38.063148  7757 convert_imageset.cpp:143] Processed 9000 files.\n",
      "E0724 18:26:38.363109  7757 convert_imageset.cpp:143] Processed 10000 files.\n",
      "E0724 18:26:38.663179  7757 convert_imageset.cpp:143] Processed 11000 files.\n",
      "E0724 18:26:38.963126  7757 convert_imageset.cpp:143] Processed 12000 files.\n",
      "E0724 18:26:39.252086  7757 convert_imageset.cpp:143] Processed 13000 files.\n",
      "E0724 18:26:39.540889  7757 convert_imageset.cpp:143] Processed 14000 files.\n",
      "E0724 18:26:39.829879  7757 convert_imageset.cpp:143] Processed 15000 files.\n",
      "E0724 18:26:40.140955  7757 convert_imageset.cpp:143] Processed 16000 files.\n",
      "E0724 18:26:40.452132  7757 convert_imageset.cpp:143] Processed 17000 files.\n",
      "E0724 18:26:40.740984  7757 convert_imageset.cpp:143] Processed 18000 files.\n",
      "E0724 18:26:41.041059  7757 convert_imageset.cpp:143] Processed 19000 files.\n",
      "E0724 18:26:41.352115  7757 convert_imageset.cpp:143] Processed 20000 files.\n",
      "E0724 18:26:41.682333  7757 convert_imageset.cpp:143] Processed 21000 files.\n",
      "E0724 18:26:41.996582  7757 convert_imageset.cpp:143] Processed 22000 files.\n",
      "E0724 18:26:42.296658  7757 convert_imageset.cpp:143] Processed 23000 files.\n",
      "E0724 18:26:42.585464  7757 convert_imageset.cpp:143] Processed 24000 files.\n",
      "E0724 18:26:42.896689  7757 convert_imageset.cpp:143] Processed 25000 files.\n",
      "E0724 18:26:43.185515  7757 convert_imageset.cpp:143] Processed 26000 files.\n",
      "E0724 18:26:43.485591  7757 convert_imageset.cpp:143] Processed 27000 files.\n",
      "E0724 18:26:44.152220  7757 convert_imageset.cpp:143] Processed 28000 files.\n",
      "E0724 18:26:44.441181  7757 convert_imageset.cpp:143] Processed 29000 files.\n",
      "E0724 18:26:44.718911  7757 convert_imageset.cpp:143] Processed 30000 files.\n",
      "E0724 18:26:45.019019  7757 convert_imageset.cpp:143] Processed 31000 files.\n",
      "E0724 18:26:45.352284  7757 convert_imageset.cpp:143] Processed 32000 files.\n",
      "E0724 18:26:45.641234  7757 convert_imageset.cpp:143] Processed 33000 files.\n",
      "E0724 18:26:45.963404  7757 convert_imageset.cpp:143] Processed 34000 files.\n",
      "E0724 18:26:46.263487  7757 convert_imageset.cpp:143] Processed 35000 files.\n",
      "E0724 18:26:46.563424  7757 convert_imageset.cpp:143] Processed 36000 files.\n",
      "E0724 18:26:46.863530  7757 convert_imageset.cpp:143] Processed 37000 files.\n",
      "E0724 18:26:47.163470  7757 convert_imageset.cpp:143] Processed 38000 files.\n",
      "E0724 18:26:47.474661  7757 convert_imageset.cpp:143] Processed 39000 files.\n",
      "E0724 18:26:47.785715  7757 convert_imageset.cpp:143] Processed 40000 files.\n",
      "E0724 18:26:48.096876  7757 convert_imageset.cpp:143] Processed 41000 files.\n",
      "E0724 18:26:48.430174  7757 convert_imageset.cpp:143] Processed 42000 files.\n",
      "E0724 18:26:48.752470  7757 convert_imageset.cpp:143] Processed 43000 files.\n",
      "E0724 18:26:49.063539  7757 convert_imageset.cpp:143] Processed 44000 files.\n",
      "E0724 18:26:49.363598  7757 convert_imageset.cpp:143] Processed 45000 files.\n",
      "I0724 18:26:49.628402  7761 convert_imageset.cpp:79] Shuffling data\n",
      "I0724 18:26:49.784503  7761 convert_imageset.cpp:82] A total of 5000 images.\n",
      "I0724 18:26:49.784770  7761 db.cpp:34] Opened lmdb /home/sandiego/Programas/datasets/cifar10/cifar_val_lmdb\n",
      "E0724 18:26:49.996245  7761 convert_imageset.cpp:143] Processed 1000 files.\n",
      "E0724 18:26:50.185055  7761 convert_imageset.cpp:143] Processed 2000 files.\n",
      "E0724 18:26:50.374022  7761 convert_imageset.cpp:143] Processed 3000 files.\n",
      "E0724 18:26:50.585073  7761 convert_imageset.cpp:143] Processed 4000 files.\n",
      "E0724 18:26:50.785150  7761 convert_imageset.cpp:143] Processed 5000 files.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/usr/bin/env sh\n",
    "\n",
    "# Ruta donde se guardaran los archivos LMDB\n",
    "OUTPUT=/home/sandiego/Programas/datasets/cifar10\n",
    "\n",
    "# Ruta donde se encuentran los datos a transformar\n",
    "DATA=/home/sandiego/Programas/datasets/cifar10\n",
    "\n",
    "# Ruta de la carpeta TOOLS en la instalación de Caffe\n",
    "TOOLS=/home/sandiego/Programas/caffe/build/tools\n",
    "\n",
    "TRAIN_DATA_ROOT=$DATA/train/\n",
    "VAL_DATA_ROOT=$DATA/val/\n",
    "\n",
    "echo \"Creating train lmdb...\"\n",
    "\n",
    "GLOG_logtostderr=1 $TOOLS/convert_imageset \\\n",
    "    --shuffle \\\n",
    "    $TRAIN_DATA_ROOT \\\n",
    "    $DATA/train/train.txt \\\n",
    "    $OUTPUT/cifar_train_lmdb\n",
    "\n",
    "echo \"Creating val lmdb...\"\n",
    "\n",
    "GLOG_logtostderr=1 $TOOLS/convert_imageset \\\n",
    "    --shuffle \\\n",
    "    $VAL_DATA_ROOT \\\n",
    "    $DATA/val/val.txt \\\n",
    "    $OUTPUT/cifar_val_lmdb\n",
    "\n",
    "echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##2. Elegir una estructura de red\n",
    "\n",
    "<img src=\"imagenes/mylenet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1 Data Layer \n",
    "\n",
    "``` python\n",
    "                layer {\n",
    "                  name: \"data\"\n",
    "                  type: \"Data\"\n",
    "                  top: \"data\"\n",
    "                  top: \"label\"\n",
    "                  include {\n",
    "                    phase: TRAIN\n",
    "                  }\n",
    "                  transform_param {\n",
    "                    # mean_file: \"mean.binaryproto\"\n",
    "                    # mirror: true\n",
    "                    # crop_size: 28\n",
    "                    # scale: 0,00390625\n",
    "                  }\n",
    "                  data_param {\n",
    "                    source: \"cifar_train_lmdb\"\n",
    "                    batch_size: 100\n",
    "                    backend: LMDB\n",
    "                  }\n",
    "                }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2 Convolution Layer\n",
    "\n",
    "<img src=\"imagenes/convolution_text.png\" align=left>\n",
    "<img src=\"imagenes/convolution.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.3 Rectified Linear Layer\n",
    "\n",
    "<img src=\"imagenes/relu_text.png\" align=left>\n",
    "<img src=\"imagenes/relu.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.4 Pooling Layer\n",
    "\n",
    "\n",
    "<img src=\"imagenes/pooling_text.png\" align=left>\n",
    "<img src=\"imagenes/pooling.gif\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.5 Fully Connected Layer\n",
    "\n",
    "<img src=\"imagenes/fully_connected_text.png\" align=left>\n",
    "<img src=\"imagenes/fully_connected.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##3. Definir un solver para guiar el entrenamiento\n",
    "\n",
    "\n",
    "``` python\n",
    "\n",
    "# Con este cubrimos todas las imagenes de prueba -> batch_size * test_iter > test images\n",
    "test_iter: 10\n",
    "# A qué intervalos realizaremos las pruebas\n",
    "test_interval: 88 \n",
    "# A qué intervalo mostrar el valor de la función de costo\n",
    "display: 100\n",
    "# Número máximo de iteraciones\n",
    "max_iter: 4000 \n",
    "# Tasa de aprendizaje de la red\n",
    "base_lr: 0.01 \n",
    "# Política de Aprendizaje\n",
    "lr_policy: \"step\"\n",
    "gamma: 0.1\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "stepsize: 500\n",
    "# Intervalo para guardar resultados intermedios\n",
    "snapshot: 2000\n",
    "snapshot_prefix: \"snapshot\"\n",
    "# Red que usaremos\n",
    "net: \"train_val.prototxt\"\n",
    "# Modo de trabajo\n",
    "solver_mode: GPU # CPU o GPU\n",
    "solver_type: SGD # SGD, NAG y Adagrad\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##4. Entrenar la red y evaluar la precisión.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0803 09:35:11.656519  3249 caffe.cpp:155] Using GPUs 0\n",
      "F0803 09:35:11.902160  3249 common.cpp:141] Check failed: error == cudaSuccess (38 vs. 0)  no CUDA-capable device is detected\n",
      "*** Check failure stack trace: ***\n",
      "    @     0x7fd3492bfdaa  (unknown)\n",
      "    @     0x7fd3492bfce4  (unknown)\n",
      "    @     0x7fd3492bf6e6  (unknown)\n",
      "    @     0x7fd3492c2687  (unknown)\n",
      "    @     0x7fd3498840a3  caffe::Caffe::SetDevice()\n",
      "    @           0x4082a6  train()\n",
      "    @           0x406091  main\n",
      "    @     0x7fd3487d1ec5  (unknown)\n",
      "    @           0x4066bb  (unknown)\n",
      "    @              (nil)  (unknown)\n",
      "Aborted\n"
     ]
    }
   ],
   "source": [
    "!/home/sandiego/Programas/caffe/build/tools/caffe train \\\n",
    "    --solver=/home/sandiego/septiembre/caffe/train_caffe/solver.prototxt \\\n",
    "    --gpu 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Entrenamiento con Digits\n",
    "\n",
    "#### Sesión interactiva\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mejorar resultados de entrenamiento con Digits\n",
    "\n",
    "<img src=\"imagenes/beagle.jpg\">\n",
    "\n",
    "---\n",
    "\n",
    "##1. Primer intento\n",
    "\n",
    "<img src=\"imagenes/red1.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red1.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red1.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##2. Segundo intento\n",
    "\n",
    "<img src=\"imagenes/red2.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red2.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##3. Tercer Intento\n",
    "\n",
    "<img src=\"imagenes/red3.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red3.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##4. Cuarto Intento\n",
    "\n",
    "<img src=\"imagenes/red4.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red4.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##5. Quinto Intento\n",
    "\n",
    "<img src=\"imagenes/red5.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red5.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
