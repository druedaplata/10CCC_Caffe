{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Redes Neuronales Convolucionales\n",
    "\n",
    "##Clasificación de Imágenes con Caffe y Digits.\n",
    "\n",
    "Caffe: https://github.com/BVLC/caffe\n",
    "\n",
    "Digits: https://github.com/NVIDIA/DIGITS\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Arquitectura de una Red Neuronal Convolucional\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/mylenet.png\">\n",
    "\n",
    "Las redes Convolucionales son muy similares a las redes Neuronales normales. Están compuestas de neuronas que tienen pesos (weights) y bias que les permiten aprender. Cada neurona recibe unas entradas, realiza un producto punto y opcionalmente sigue una no-linealidad.}\n",
    "\n",
    "* Son redes con una estructura de conectividad especializada.\n",
    "\n",
    "\n",
    "* Entrenamiento supervisado.\n",
    "\n",
    "\n",
    "* Típicamente, tienen los siguientes elementos.\n",
    "\n",
    "  * Convolutional Layer\n",
    "  * Non-linearity\n",
    "  * Pooling Layer\n",
    "  * Fully Connected\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Convolutional Layer\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/convolution.gif\" width=400px align=center>\n",
    "\n",
    "La capa convolucional consiste en un grupo de filtros.\n",
    "Estos filtros son pequeños campos receptivos que desplazamos por todo el ancho y largo de la imagen de entrada, produciendo un mapa de características. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Conectividad Local\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/local_connected.png\" width=70%>\n",
    "\n",
    "La idea consiste en conectar cada neurona en la capa de convolución con una región pequeña en la imagen de entrada, pero conectada a todos los canales de color. <br>Esta región la llamaremos el **campo receptivo (F)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Disposición Espacial\n",
    "\n",
    "Consiste de 3 hiperparámetros que controlan la salida que obtenemos de la red convolucional.\n",
    "\n",
    "1. **Depth (Profundidad):** Controla el número de neuronas en la capa convolucional que se conectan a la misma región en la imagen de entrada. Nos referimos a un grupo de neuronas que están conectadas a la misma región como una **columna de profundidad**.\n",
    "\n",
    "2. **Stride:** Este parámetro especifica el \"paso\" que dará nuestro campo receptivo para ubicar una nueva columna de profundidad.\n",
    "\n",
    "3. **Zero-padding:** En ocasiones será conveniente definir los bordes de la entrada a la red en ceros, ya que esto nos permitirá controlar el tamaño de la salida en la red neuronal.\n",
    "\n",
    "La salida de la capa convolucional se calcula de la siguiente manera:\n",
    "\n",
    "\\begin{equation}\n",
    "  W_{output} = [(W_{input}- F + 2P)/S + 1] \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "  H_{output} = [(H_{input} - F + 2P)/S + 1 ]  \n",
    "\\end{equation}\n",
    "\n",
    "Por lo tanto, si tenemos la siguiente situación:\n",
    "\n",
    "\\begin{equation}\n",
    "  Input = 227_{width} * 227_{height} * 3_{rgb}\n",
    "\\end{equation}\n",
    "\n",
    "...y definimos los hiperparámetros:\n",
    "\n",
    "\\begin{align}\n",
    "  Field = 11\\\\\n",
    "  Depth = 96\\\\\n",
    "  Stride = 4\\\\\n",
    "  Zero-padding = 0\n",
    "\\end{align}\n",
    "\n",
    "La salida de esta capa tendrá las siguientes dimensiones:\n",
    "\n",
    "\\begin{equation}\n",
    "  Output = 55_{width} * 55_{height} * 96_{neurons}\n",
    "\\end{equation}\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/conv_out_1.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Pesos y bias compartidos\n",
    "\n",
    "Hasta el momento cada neurona en nuestra red convolucional tiene $1$ bias y $11$x$11$ pesos conectados al campo perceptivo. \n",
    "\n",
    "Puesto que las imágenes naturales tienen propiedades **estacionarias**, es decir que las características aprendidas en una parte de la imagen serán útiles en cualquier otra parte.\n",
    "\n",
    "Gracias a esto podemos usar el mismo bias y $11$x$11$ pesos en todas las neuronas de la primera capa para que busquen, por ejemplo, una linea vertical en toda la imagen. Y usaremos pesos diferentes en las demas capas de neuronas para buscar diferentes características.\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/conv_out_2.png\" >\n",
    "\n",
    "Despues del entrenamiento estos $96$ pesos de $11$x$11$ aprenderán a reconocer características simples de la imagen.\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/features_conv1.jpg\" width=250>\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Non-linearity Layer\n",
    "\n",
    "Podemos definir la salida de una capa en la red neuronal como $\\bar o$ que sería el resultado\n",
    "de una función de activación $f()$ aplicada al producto entre la entrada\n",
    "\n",
    "$\\bar x=\\begin{bmatrix}x_1\\\\x_2\\\\.\\\\.\\\\x_3\\\\x_4\\end{bmatrix}$ y los pesos de la capa \n",
    "$W=\\begin{bmatrix}w_{00} & w_{01} & . & . & w_{0n} & b_0\\\\\n",
    "                  w_{10} & w_{11} & . & . & w_{1n} & b_1\\\\\n",
    "                  . & . & . & . & . & .\\\\\n",
    "                  w_{n0} & w_{n1} & . & . & w_{nn} & b_n\\\\\\end{bmatrix}$ produciendo $\\bar o = f(W\\bar x)$\n",
    "                  \n",
    "Lo que podemos observar en este caso es que si usamos activación **lineal**, entonces una red neuronal con 2 capas se describiría de la siguiente forma:\n",
    "\n",
    "$\\bar o_1 = W_1\\bar x$\n",
    "\n",
    "$\\bar o_2 = W_2\\bar o_1 = W_2W_1\\bar x$\n",
    "\n",
    "Esto significa que añadir mas capas hara el sistemas mas lento y complicado, pero no mas expresivo. Esto no se cumple cuando usamos una función de activación **no lineal**.\n",
    "\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/relu.png\" style=\"float: left\">\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/relu.png\" style=\"float: left\" width=300>\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/tanh2.png\" style=\"float: left\" width=300>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "\n",
    "##Pooling Layer\n",
    "\n",
    "La función de esta capa es reducir el tamaño de la representación entregada por la capa convolucional para disminuir la cantidad de parámetros y disminuir el tiempo de calculo en la red.\n",
    "\n",
    "\\begin{equation}\n",
    "  W_{output} = [(W_{input}- F)/S + 1] \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "  H_{output} = [(H_{input}- F)/S + 1] \n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "  D_{input} = D_{output}\n",
    "\\end{equation}\n",
    "<br>\n",
    "\n",
    "<div style=\"float: right\">\n",
    "<img src=\"https://bytebucket.org/sandiego206/10ccc_caffe/raw/c13e96d59673ebf1024e206b588362ff8bacd11a/caffe/imagenes/conv_out_1.png\" style=\"float: left\">\n",
    "<img src=\"imagenes/pool_out_1.png\" style=\"float: left\" width=20%>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"imagenes/pooling.png\" width=50%>\n",
    "\n",
    "Al igual que la red convolucional, recibe hiperparámetros que controlan su funcionamiento, el campo receptivo $F$ y el paso $S$. Frecuentemente se usa un campo receptivo pequeño, dado que con un mayor tamaño se perdería la representación en las características de la red."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##Fully Connected Layer\n",
    "\n",
    "Finalmente, después de varias capas convolucionales, no linealidades y posiblemente pooling, el razonamiento de alto nivel es realizado por las capas fully connected. Estas toman todas las neuronas en la capa anterior (ya sea convolucional, pooling o fully connected) y las conecta con todas las neuronas que tiene. \n",
    "\n",
    "<img src=\"imagenes/fully_connected.gif\">\n",
    "\n",
    "La última capa fully connected en el caso de clasificación de imágenes tendrá un número de neuronas igual a la cantidad de clases que estamos clasificando.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#Entrenar una CNN usando CAFFE\n",
    "\n",
    "1. Seleccionar un dataset.\n",
    "2. Crear una estructura de red.\n",
    "3. Definir los hiperparámetros que guiarán el entrenamiento.\n",
    "4. Entrenar la red y evaluar la precisión sobre un dataset de prueba.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "##1. Seleccionar un dataset\n",
    "\n",
    "Para este ejercicio usamos el dataset **Cifar 10**, que contiene objetos y animales de 10 categorias. El dataset consiste de 60000 imágenes de de 32x32. Para este ejercicio usaremos 25000 imágenes para entrenamiento y 25000 en validación.\n",
    "\n",
    "<img src=\"imagenes/cifar_10.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "###1.1 Convertir a formato LMDB\n",
    "\n",
    "* Un archivo con la ruta a todas las imagenes y la categoría a la que pertenecen.\n",
    "\n",
    "        imagen_001.jpg 0\n",
    "        imagen_002.jpg 1\n",
    "        imagen_003.jpg 1\n",
    "        imagen_004.jpg 2\n",
    "        imagen_005.jpg 2\n",
    "        imagen_006.jpg 0\n",
    "        imagen_007.jpg 3\n",
    "        imagen_008.jpg 4\n",
    "\n",
    "\n",
    "* Las imágenes deben tener el mismo tamaño.\n",
    "* Convertimos las imagenes en formato LMDB para mejorar el tiempo de acceso de CAFFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train lmdb...\n",
      "Creating val lmdb...\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0724 18:26:35.286201  7757 convert_imageset.cpp:79] Shuffling data\n",
      "I0724 18:26:35.444700  7757 convert_imageset.cpp:82] A total of 45000 images.\n",
      "I0724 18:26:35.444989  7757 db.cpp:34] Opened lmdb /home/sandiego/Programas/datasets/cifar10/cifar_train_lmdb\n",
      "E0724 18:26:35.718617  7757 convert_imageset.cpp:143] Processed 1000 files.\n",
      "E0724 18:26:36.007438  7757 convert_imageset.cpp:143] Processed 2000 files.\n",
      "E0724 18:26:36.285279  7757 convert_imageset.cpp:143] Processed 3000 files.\n",
      "E0724 18:26:36.574103  7757 convert_imageset.cpp:143] Processed 4000 files.\n",
      "E0724 18:26:36.874199  7757 convert_imageset.cpp:143] Processed 5000 files.\n",
      "E0724 18:26:37.174136  7757 convert_imageset.cpp:143] Processed 6000 files.\n",
      "E0724 18:26:37.463117  7757 convert_imageset.cpp:143] Processed 7000 files.\n",
      "E0724 18:26:37.763088  7757 convert_imageset.cpp:143] Processed 8000 files.\n",
      "E0724 18:26:38.063148  7757 convert_imageset.cpp:143] Processed 9000 files.\n",
      "E0724 18:26:38.363109  7757 convert_imageset.cpp:143] Processed 10000 files.\n",
      "E0724 18:26:38.663179  7757 convert_imageset.cpp:143] Processed 11000 files.\n",
      "E0724 18:26:38.963126  7757 convert_imageset.cpp:143] Processed 12000 files.\n",
      "E0724 18:26:39.252086  7757 convert_imageset.cpp:143] Processed 13000 files.\n",
      "E0724 18:26:39.540889  7757 convert_imageset.cpp:143] Processed 14000 files.\n",
      "E0724 18:26:39.829879  7757 convert_imageset.cpp:143] Processed 15000 files.\n",
      "E0724 18:26:40.140955  7757 convert_imageset.cpp:143] Processed 16000 files.\n",
      "E0724 18:26:40.452132  7757 convert_imageset.cpp:143] Processed 17000 files.\n",
      "E0724 18:26:40.740984  7757 convert_imageset.cpp:143] Processed 18000 files.\n",
      "E0724 18:26:41.041059  7757 convert_imageset.cpp:143] Processed 19000 files.\n",
      "E0724 18:26:41.352115  7757 convert_imageset.cpp:143] Processed 20000 files.\n",
      "E0724 18:26:41.682333  7757 convert_imageset.cpp:143] Processed 21000 files.\n",
      "E0724 18:26:41.996582  7757 convert_imageset.cpp:143] Processed 22000 files.\n",
      "E0724 18:26:42.296658  7757 convert_imageset.cpp:143] Processed 23000 files.\n",
      "E0724 18:26:42.585464  7757 convert_imageset.cpp:143] Processed 24000 files.\n",
      "E0724 18:26:42.896689  7757 convert_imageset.cpp:143] Processed 25000 files.\n",
      "E0724 18:26:43.185515  7757 convert_imageset.cpp:143] Processed 26000 files.\n",
      "E0724 18:26:43.485591  7757 convert_imageset.cpp:143] Processed 27000 files.\n",
      "E0724 18:26:44.152220  7757 convert_imageset.cpp:143] Processed 28000 files.\n",
      "E0724 18:26:44.441181  7757 convert_imageset.cpp:143] Processed 29000 files.\n",
      "E0724 18:26:44.718911  7757 convert_imageset.cpp:143] Processed 30000 files.\n",
      "E0724 18:26:45.019019  7757 convert_imageset.cpp:143] Processed 31000 files.\n",
      "E0724 18:26:45.352284  7757 convert_imageset.cpp:143] Processed 32000 files.\n",
      "E0724 18:26:45.641234  7757 convert_imageset.cpp:143] Processed 33000 files.\n",
      "E0724 18:26:45.963404  7757 convert_imageset.cpp:143] Processed 34000 files.\n",
      "E0724 18:26:46.263487  7757 convert_imageset.cpp:143] Processed 35000 files.\n",
      "E0724 18:26:46.563424  7757 convert_imageset.cpp:143] Processed 36000 files.\n",
      "E0724 18:26:46.863530  7757 convert_imageset.cpp:143] Processed 37000 files.\n",
      "E0724 18:26:47.163470  7757 convert_imageset.cpp:143] Processed 38000 files.\n",
      "E0724 18:26:47.474661  7757 convert_imageset.cpp:143] Processed 39000 files.\n",
      "E0724 18:26:47.785715  7757 convert_imageset.cpp:143] Processed 40000 files.\n",
      "E0724 18:26:48.096876  7757 convert_imageset.cpp:143] Processed 41000 files.\n",
      "E0724 18:26:48.430174  7757 convert_imageset.cpp:143] Processed 42000 files.\n",
      "E0724 18:26:48.752470  7757 convert_imageset.cpp:143] Processed 43000 files.\n",
      "E0724 18:26:49.063539  7757 convert_imageset.cpp:143] Processed 44000 files.\n",
      "E0724 18:26:49.363598  7757 convert_imageset.cpp:143] Processed 45000 files.\n",
      "I0724 18:26:49.628402  7761 convert_imageset.cpp:79] Shuffling data\n",
      "I0724 18:26:49.784503  7761 convert_imageset.cpp:82] A total of 5000 images.\n",
      "I0724 18:26:49.784770  7761 db.cpp:34] Opened lmdb /home/sandiego/Programas/datasets/cifar10/cifar_val_lmdb\n",
      "E0724 18:26:49.996245  7761 convert_imageset.cpp:143] Processed 1000 files.\n",
      "E0724 18:26:50.185055  7761 convert_imageset.cpp:143] Processed 2000 files.\n",
      "E0724 18:26:50.374022  7761 convert_imageset.cpp:143] Processed 3000 files.\n",
      "E0724 18:26:50.585073  7761 convert_imageset.cpp:143] Processed 4000 files.\n",
      "E0724 18:26:50.785150  7761 convert_imageset.cpp:143] Processed 5000 files.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "#!/usr/bin/env sh\n",
    "\n",
    "# Ruta donde se guardaran los archivos LMDB\n",
    "OUTPUT=/home/sandiego/Programas/datasets/cifar10\n",
    "\n",
    "# Ruta donde se encuentran los datos a transformar\n",
    "DATA=/home/sandiego/Programas/datasets/cifar10\n",
    "\n",
    "# Ruta de la carpeta TOOLS en la instalación de Caffe\n",
    "TOOLS=/home/sandiego/Programas/caffe/build/tools\n",
    "\n",
    "TRAIN_DATA_ROOT=$DATA/train/\n",
    "VAL_DATA_ROOT=$DATA/val/\n",
    "\n",
    "echo \"Creating train lmdb...\"\n",
    "\n",
    "GLOG_logtostderr=1 $TOOLS/convert_imageset \\\n",
    "    --shuffle \\\n",
    "    $TRAIN_DATA_ROOT \\\n",
    "    $DATA/train/train.txt \\\n",
    "    $OUTPUT/cifar_train_lmdb\n",
    "\n",
    "echo \"Creating val lmdb...\"\n",
    "\n",
    "GLOG_logtostderr=1 $TOOLS/convert_imageset \\\n",
    "    --shuffle \\\n",
    "    $VAL_DATA_ROOT \\\n",
    "    $DATA/val/val.txt \\\n",
    "    $OUTPUT/cifar_val_lmdb\n",
    "\n",
    "echo \"Done.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##2. Elegir una estructura de red\n",
    "\n",
    "<img src=\"imagenes/mylenet.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.1 Data Layer \n",
    "\n",
    "``` python\n",
    "                layer {\n",
    "                  name: \"data\"\n",
    "                  type: \"Data\"\n",
    "                  top: \"data\"\n",
    "                  top: \"label\"\n",
    "                  include {\n",
    "                    phase: TRAIN\n",
    "                  }\n",
    "                  transform_param {\n",
    "                    # mean_file: \"mean.binaryproto\"\n",
    "                    # mirror: true\n",
    "                    # crop_size: 28\n",
    "                    # scale: 0,00390625\n",
    "                  }\n",
    "                  data_param {\n",
    "                    source: \"cifar_train_lmdb\"\n",
    "                    batch_size: 100\n",
    "                    backend: LMDB\n",
    "                  }\n",
    "                }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.2 Convolution Layer\n",
    "\n",
    "<img src=\"imagenes/convolution_text.png\" align=left>\n",
    "<img src=\"imagenes/convolution.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.3 Rectified Linear Layer\n",
    "\n",
    "<img src=\"imagenes/relu_text.png\" align=left>\n",
    "<img src=\"imagenes/relu.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.4 Pooling Layer\n",
    "\n",
    "\n",
    "<img src=\"imagenes/pooling_text.png\" align=left>\n",
    "<img src=\"imagenes/pooling.gif\" width=70%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###2.5 Fully Connected Layer\n",
    "\n",
    "<img src=\"imagenes/fully_connected_text.png\" align=left>\n",
    "<img src=\"imagenes/fully_connected.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##3. Definir un solver para guiar el entrenamiento\n",
    "\n",
    "\n",
    "``` python\n",
    "\n",
    "# Con este cubrimos todas las imagenes de prueba -> batch_size * test_iter > test images\n",
    "test_iter: 10\n",
    "# A qué intervalos realizaremos las pruebas\n",
    "test_interval: 88 \n",
    "# A qué intervalo mostrar el valor de la función de costo\n",
    "display: 100\n",
    "# Número máximo de iteraciones\n",
    "max_iter: 4000 \n",
    "# Tasa de aprendizaje de la red\n",
    "base_lr: 0.01 \n",
    "# Política de Aprendizaje\n",
    "lr_policy: \"step\"\n",
    "gamma: 0.1\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "stepsize: 500\n",
    "# Intervalo para guardar resultados intermedios\n",
    "snapshot: 2000\n",
    "snapshot_prefix: \"snapshot\"\n",
    "# Red que usaremos\n",
    "net: \"train_val.prototxt\"\n",
    "# Modo de trabajo\n",
    "solver_mode: GPU # CPU o GPU\n",
    "solver_type: SGD # SGD, NAG y Adagrad\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##4. Entrenar la red y evaluar la precisión.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0803 11:01:56.873383  3434 caffe.cpp:155] Using GPUs 0\n",
      "I0803 11:01:58.949472  3434 solver.cpp:33] Initializing solver from parameters: \n",
      "test_iter: 10\n",
      "test_interval: 88\n",
      "base_lr: 0.0001\n",
      "display: 100\n",
      "max_iter: 2640\n",
      "lr_policy: \"step\"\n",
      "gamma: 0.1\n",
      "momentum: 0.9\n",
      "weight_decay: 0.0005\n",
      "stepsize: 872\n",
      "snapshot: 1320\n",
      "snapshot_prefix: \"snapshot\"\n",
      "solver_mode: GPU\n",
      "device_id: 0\n",
      "random_seed: 1989\n",
      "net: \"/home/sandiego/septiembre/caffe/train_caffe/train_val.prototxt\"\n",
      "solver_type: SGD\n",
      "I0803 11:01:58.949612  3434 solver.cpp:81] Creating training net from net file: /home/sandiego/septiembre/caffe/train_caffe/train_val.prototxt\n",
      "I0803 11:01:58.979674  3434 net.cpp:316] The NetState phase (0) differed from the phase (1) specified by a rule in layer data\n",
      "I0803 11:01:58.979725  3434 net.cpp:316] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy\n",
      "I0803 11:01:58.979836  3434 net.cpp:47] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TRAIN\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TRAIN\n",
      "  }\n",
      "  transform_param {\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"/home/sandiego/Programas/datasets/cifar10/cifar_train_lmdb\"\n",
      "    batch_size: 512\n",
      "    backend: LMDB\n",
      "    prefetch: 4\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 10\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "I0803 11:01:58.980155  3434 layer_factory.hpp:75] Creating layer data\n",
      "I0803 11:01:58.999734  3434 net.cpp:99] Creating Layer data\n",
      "I0803 11:01:58.999790  3434 net.cpp:409] data -> data\n",
      "I0803 11:01:59.000041  3434 net.cpp:409] data -> label\n",
      "I0803 11:01:59.000073  3434 net.cpp:131] Setting up data\n",
      "I0803 11:01:59.051571  3440 db.cpp:34] Opened lmdb /home/sandiego/Programas/datasets/cifar10/cifar_train_lmdb\n",
      "I0803 11:01:59.079550  3434 data_layer.cpp:60] output data size: 512,3,32,32\n",
      "I0803 11:01:59.092876  3434 net.cpp:140] Top shape: 512 3 32 32 (1572864)\n",
      "I0803 11:01:59.092916  3434 net.cpp:140] Top shape: 512 (512)\n",
      "I0803 11:01:59.092931  3434 layer_factory.hpp:75] Creating layer conv1\n",
      "I0803 11:01:59.092957  3434 net.cpp:99] Creating Layer conv1\n",
      "I0803 11:01:59.092968  3434 net.cpp:453] conv1 <- data\n",
      "I0803 11:01:59.092989  3434 net.cpp:409] conv1 -> conv1\n",
      "I0803 11:01:59.093013  3434 net.cpp:131] Setting up conv1\n",
      "I0803 11:01:59.098619  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.099395  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.123556  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.127230  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.151387  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.153398  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.177618  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.179613  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.205457  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.207449  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:01:59.231528  3441 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:00.930907  3434 net.cpp:140] Top shape: 512 64 32 32 (33554432)\n",
      "I0803 11:02:00.930965  3434 layer_factory.hpp:75] Creating layer relu1\n",
      "I0803 11:02:00.930982  3434 net.cpp:99] Creating Layer relu1\n",
      "I0803 11:02:00.931016  3434 net.cpp:453] relu1 <- conv1\n",
      "I0803 11:02:00.931030  3434 net.cpp:396] relu1 -> conv1 (in-place)\n",
      "I0803 11:02:00.931041  3434 net.cpp:131] Setting up relu1\n",
      "I0803 11:02:00.931350  3434 net.cpp:140] Top shape: 512 64 32 32 (33554432)\n",
      "I0803 11:02:00.931368  3434 layer_factory.hpp:75] Creating layer pool1\n",
      "I0803 11:02:00.931385  3434 net.cpp:99] Creating Layer pool1\n",
      "I0803 11:02:00.931393  3434 net.cpp:453] pool1 <- conv1\n",
      "I0803 11:02:00.931404  3434 net.cpp:409] pool1 -> pool1\n",
      "I0803 11:02:00.931416  3434 net.cpp:131] Setting up pool1\n",
      "I0803 11:02:00.936666  3434 net.cpp:140] Top shape: 512 64 16 16 (8388608)\n",
      "I0803 11:02:00.936707  3434 layer_factory.hpp:75] Creating layer fc8\n",
      "I0803 11:02:00.936730  3434 net.cpp:99] Creating Layer fc8\n",
      "I0803 11:02:00.936740  3434 net.cpp:453] fc8 <- pool1\n",
      "I0803 11:02:00.936753  3434 net.cpp:409] fc8 -> fc8\n",
      "I0803 11:02:00.936770  3434 net.cpp:131] Setting up fc8\n",
      "I0803 11:02:00.941534  3434 net.cpp:140] Top shape: 512 10 (5120)\n",
      "I0803 11:02:00.941561  3434 layer_factory.hpp:75] Creating layer loss\n",
      "I0803 11:02:00.941575  3434 net.cpp:99] Creating Layer loss\n",
      "I0803 11:02:00.941581  3434 net.cpp:453] loss <- fc8\n",
      "I0803 11:02:00.941587  3434 net.cpp:453] loss <- label\n",
      "I0803 11:02:00.941606  3434 net.cpp:409] loss -> loss\n",
      "I0803 11:02:00.941614  3434 net.cpp:131] Setting up loss\n",
      "I0803 11:02:00.941624  3434 layer_factory.hpp:75] Creating layer loss\n",
      "I0803 11:02:00.941781  3434 net.cpp:140] Top shape: (1)\n",
      "I0803 11:02:00.941804  3434 net.cpp:145]     with loss weight 1\n",
      "I0803 11:02:00.941843  3434 net.cpp:213] loss needs backward computation.\n",
      "I0803 11:02:00.941853  3434 net.cpp:213] fc8 needs backward computation.\n",
      "I0803 11:02:00.941858  3434 net.cpp:213] pool1 needs backward computation.\n",
      "I0803 11:02:00.941864  3434 net.cpp:213] relu1 needs backward computation.\n",
      "I0803 11:02:00.941869  3434 net.cpp:213] conv1 needs backward computation.\n",
      "I0803 11:02:00.941874  3434 net.cpp:217] data does not need backward computation.\n",
      "I0803 11:02:00.941879  3434 net.cpp:260] This network produces output loss\n",
      "I0803 11:02:00.941887  3434 net.cpp:529] Collecting Learning Rate and Weight Decay.\n",
      "I0803 11:02:00.941905  3434 net.cpp:274] Network initialization done.\n",
      "I0803 11:02:00.941910  3434 net.cpp:275] Memory required for data: 308303876\n",
      "I0803 11:02:00.942193  3434 solver.cpp:167] Creating test net (#0) specified by net file: /home/sandiego/septiembre/caffe/train_caffe/train_val.prototxt\n",
      "I0803 11:02:00.942241  3434 net.cpp:316] The NetState phase (1) differed from the phase (0) specified by a rule in layer data\n",
      "I0803 11:02:00.942315  3434 net.cpp:47] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "}\n",
      "layer {\n",
      "  name: \"data\"\n",
      "  type: \"Data\"\n",
      "  top: \"data\"\n",
      "  top: \"label\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "  transform_param {\n",
      "  }\n",
      "  data_param {\n",
      "    source: \"/home/sandiego/Programas/datasets/cifar10/cifar_val_lmdb\"\n",
      "    batch_size: 512\n",
      "    backend: LMDB\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 64\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    stride: 1\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 2\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 10\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"loss\"\n",
      "  type: \"SoftmaxWithLoss\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"loss\"\n",
      "}\n",
      "layer {\n",
      "  name: \"accuracy\"\n",
      "  type: \"Accuracy\"\n",
      "  bottom: \"fc8\"\n",
      "  bottom: \"label\"\n",
      "  top: \"accuracy\"\n",
      "  include {\n",
      "    phase: TEST\n",
      "  }\n",
      "}\n",
      "I0803 11:02:00.942610  3434 layer_factory.hpp:75] Creating layer data\n",
      "I0803 11:02:00.942894  3434 net.cpp:99] Creating Layer data\n",
      "I0803 11:02:00.942905  3434 net.cpp:409] data -> data\n",
      "I0803 11:02:00.942925  3434 net.cpp:409] data -> label\n",
      "I0803 11:02:00.942935  3434 net.cpp:131] Setting up data\n",
      "I0803 11:02:00.984268  3442 db.cpp:34] Opened lmdb /home/sandiego/Programas/datasets/cifar10/cifar_val_lmdb\n",
      "I0803 11:02:00.997992  3434 data_layer.cpp:60] output data size: 512,3,32,32\n",
      "I0803 11:02:01.007618  3434 net.cpp:140] Top shape: 512 3 32 32 (1572864)\n",
      "I0803 11:02:01.007647  3434 net.cpp:140] Top shape: 512 (512)\n",
      "I0803 11:02:01.007658  3434 layer_factory.hpp:75] Creating layer label_data_1_split\n",
      "I0803 11:02:01.007676  3434 net.cpp:99] Creating Layer label_data_1_split\n",
      "I0803 11:02:01.007684  3434 net.cpp:453] label_data_1_split <- label\n",
      "I0803 11:02:01.007694  3434 net.cpp:409] label_data_1_split -> label_data_1_split_0\n",
      "I0803 11:02:01.007706  3434 net.cpp:409] label_data_1_split -> label_data_1_split_1\n",
      "I0803 11:02:01.007715  3434 net.cpp:131] Setting up label_data_1_split\n",
      "I0803 11:02:01.007726  3434 net.cpp:140] Top shape: 512 (512)\n",
      "I0803 11:02:01.007733  3434 net.cpp:140] Top shape: 512 (512)\n",
      "I0803 11:02:01.007740  3434 layer_factory.hpp:75] Creating layer conv1\n",
      "I0803 11:02:01.007750  3434 net.cpp:99] Creating Layer conv1\n",
      "I0803 11:02:01.007756  3434 net.cpp:453] conv1 <- data\n",
      "I0803 11:02:01.007764  3434 net.cpp:409] conv1 -> conv1\n",
      "I0803 11:02:01.007773  3434 net.cpp:131] Setting up conv1\n",
      "I0803 11:02:01.008535  3434 net.cpp:140] Top shape: 512 64 32 32 (33554432)\n",
      "I0803 11:02:01.008563  3434 layer_factory.hpp:75] Creating layer relu1\n",
      "I0803 11:02:01.008575  3434 net.cpp:99] Creating Layer relu1\n",
      "I0803 11:02:01.008582  3434 net.cpp:453] relu1 <- conv1\n",
      "I0803 11:02:01.008591  3434 net.cpp:396] relu1 -> conv1 (in-place)\n",
      "I0803 11:02:01.008600  3434 net.cpp:131] Setting up relu1\n",
      "I0803 11:02:01.008839  3434 net.cpp:140] Top shape: 512 64 32 32 (33554432)\n",
      "I0803 11:02:01.008852  3434 layer_factory.hpp:75] Creating layer pool1\n",
      "I0803 11:02:01.008865  3434 net.cpp:99] Creating Layer pool1\n",
      "I0803 11:02:01.008885  3434 net.cpp:453] pool1 <- conv1\n",
      "I0803 11:02:01.008896  3434 net.cpp:409] pool1 -> pool1\n",
      "I0803 11:02:01.008906  3434 net.cpp:131] Setting up pool1\n",
      "I0803 11:02:01.009708  3434 net.cpp:140] Top shape: 512 64 16 16 (8388608)\n",
      "I0803 11:02:01.009737  3434 layer_factory.hpp:75] Creating layer fc8\n",
      "I0803 11:02:01.009755  3434 net.cpp:99] Creating Layer fc8\n",
      "I0803 11:02:01.009766  3434 net.cpp:453] fc8 <- pool1\n",
      "I0803 11:02:01.009804  3434 net.cpp:409] fc8 -> fc8\n",
      "I0803 11:02:01.009819  3434 net.cpp:131] Setting up fc8\n",
      "I0803 11:02:01.010370  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.011934  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.014094  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.016307  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.017488  3434 net.cpp:140] Top shape: 512 10 (5120)\n",
      "I0803 11:02:01.017554  3434 layer_factory.hpp:75] Creating layer fc8_fc8_0_split\n",
      "I0803 11:02:01.017570  3434 net.cpp:99] Creating Layer fc8_fc8_0_split\n",
      "I0803 11:02:01.017580  3434 net.cpp:453] fc8_fc8_0_split <- fc8\n",
      "I0803 11:02:01.017590  3434 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_0\n",
      "I0803 11:02:01.017602  3434 net.cpp:409] fc8_fc8_0_split -> fc8_fc8_0_split_1\n",
      "I0803 11:02:01.017616  3434 net.cpp:131] Setting up fc8_fc8_0_split\n",
      "I0803 11:02:01.017627  3434 net.cpp:140] Top shape: 512 10 (5120)\n",
      "I0803 11:02:01.017637  3434 net.cpp:140] Top shape: 512 10 (5120)\n",
      "I0803 11:02:01.017645  3434 layer_factory.hpp:75] Creating layer loss\n",
      "I0803 11:02:01.017654  3434 net.cpp:99] Creating Layer loss\n",
      "I0803 11:02:01.017663  3434 net.cpp:453] loss <- fc8_fc8_0_split_0\n",
      "I0803 11:02:01.017671  3434 net.cpp:453] loss <- label_data_1_split_0\n",
      "I0803 11:02:01.017680  3434 net.cpp:409] loss -> loss\n",
      "I0803 11:02:01.017690  3434 net.cpp:131] Setting up loss\n",
      "I0803 11:02:01.017700  3434 layer_factory.hpp:75] Creating layer loss\n",
      "I0803 11:02:01.017856  3434 net.cpp:140] Top shape: (1)\n",
      "I0803 11:02:01.017876  3434 net.cpp:145]     with loss weight 1\n",
      "I0803 11:02:01.017915  3434 layer_factory.hpp:75] Creating layer accuracy\n",
      "I0803 11:02:01.017933  3434 net.cpp:99] Creating Layer accuracy\n",
      "I0803 11:02:01.017942  3434 net.cpp:453] accuracy <- fc8_fc8_0_split_1\n",
      "I0803 11:02:01.017951  3434 net.cpp:453] accuracy <- label_data_1_split_1\n",
      "I0803 11:02:01.017961  3434 net.cpp:409] accuracy -> accuracy\n",
      "I0803 11:02:01.017971  3434 net.cpp:131] Setting up accuracy\n",
      "I0803 11:02:01.017983  3434 net.cpp:140] Top shape: (1)\n",
      "I0803 11:02:01.017992  3434 net.cpp:217] accuracy does not need backward computation.\n",
      "I0803 11:02:01.017998  3434 net.cpp:213] loss needs backward computation.\n",
      "I0803 11:02:01.018007  3434 net.cpp:213] fc8_fc8_0_split needs backward computation.\n",
      "I0803 11:02:01.018014  3434 net.cpp:213] fc8 needs backward computation.\n",
      "I0803 11:02:01.018021  3434 net.cpp:213] pool1 needs backward computation.\n",
      "I0803 11:02:01.018028  3434 net.cpp:213] relu1 needs backward computation.\n",
      "I0803 11:02:01.018035  3434 net.cpp:213] conv1 needs backward computation.\n",
      "I0803 11:02:01.018043  3434 net.cpp:217] label_data_1_split does not need backward computation.\n",
      "I0803 11:02:01.018051  3434 net.cpp:217] data does not need backward computation.\n",
      "I0803 11:02:01.018057  3434 net.cpp:260] This network produces output accuracy\n",
      "I0803 11:02:01.018067  3434 net.cpp:260] This network produces output loss\n",
      "I0803 11:02:01.018090  3434 net.cpp:529] Collecting Learning Rate and Weight Decay.\n",
      "I0803 11:02:01.018105  3434 net.cpp:274] Network initialization done.\n",
      "I0803 11:02:01.018117  3434 net.cpp:275] Memory required for data: 308348936\n",
      "I0803 11:02:01.018172  3434 solver.cpp:45] Solver scaffolding done.\n",
      "I0803 11:02:01.018193  3434 caffe.cpp:175] Starting Optimization\n",
      "I0803 11:02:01.018206  3434 solver.cpp:269] Solving \n",
      "I0803 11:02:01.018213  3434 solver.cpp:270] Learning Rate Policy: step\n",
      "I0803 11:02:01.018244  3434 solver.cpp:314] Iteration 0, Testing net (#0)\n",
      "I0803 11:02:01.018632  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.020043  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.022181  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.024526  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.026602  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.028887  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.032786  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.035006  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.037192  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.039384  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.041662  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.045565  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.048948  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.049880  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.052044  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.054132  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.057929  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.060114  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.062309  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.064498  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.066676  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.070579  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.073003  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.075134  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.077420  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.079365  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.083178  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.083498  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.085402  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.087306  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.092679  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.095895  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.098104  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.100229  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.102398  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.104595  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.108609  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.110826  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.113067  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.115278  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.117475  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.121269  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.123112  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.123548  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.125802  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.127840  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.130594  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.133718  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.135902  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.138105  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.140329  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.142628  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.146438  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.148605  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.150797  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.152997  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.155194  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.159158  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.161445  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.161566  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.163627  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.165717  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.168081  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.168782  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.173502  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.174926  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.177300  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.179518  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.181705  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.185566  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.187662  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.189821  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.192018  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.194211  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.198086  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.200291  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.202453  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.203905  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.204666  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.207022  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.211068  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.213810  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.215523  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.217723  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.219885  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.223379  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.225692  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.227933  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.230141  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.232375  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.236079  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.238183  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.240375  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.242560  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.242823  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.244951  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.248693  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.250861  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.253763  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.255220  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.257378  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.261415  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.263653  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.265838  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.268034  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.270239  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.273902  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.276288  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.278534  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.280640  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.282707  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.283279  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.286664  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.288903  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.291113  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.294018  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.295414  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.299240  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.301362  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.303540  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.305760  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.307945  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.310145  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.314281  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.316462  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.318639  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.320828  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.322819  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.323256  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.327035  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.329118  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.329581  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.333645  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.336941  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.337632  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.341207  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.343166  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.345150  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.347126  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.349109  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.351135  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.354723  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.356683  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.358681  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.360818  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.362598  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.366299  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.366431  3434 blocking_queue.cpp:50] Data layer prefetch queue empty\n",
      "I0803 11:02:01.368224  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.370194  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.372861  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.374164  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.376114  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.379786  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.381783  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.383724  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.385783  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.387686  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.391310  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.393303  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.395269  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.397260  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.399302  3443 blocking_queue.cpp:50] Waiting for data\n",
      "I0803 11:02:01.433495  3434 solver.cpp:363]     Test net output #0: accuracy = 0.110352\n",
      "I0803 11:02:01.433549  3434 solver.cpp:363]     Test net output #1: loss = 14.4475 (* 1 = 14.4475 loss)\n",
      "I0803 11:02:01.467854  3434 solver.cpp:217] Iteration 0, loss = 15.1049\n",
      "I0803 11:02:01.467903  3434 solver.cpp:234]     Train net output #0: loss = 15.1049 (* 1 = 15.1049 loss)\n",
      "I0803 11:02:01.520242  3434 solver.cpp:511] Iteration 0 (0/s), lr = 0.0001\n",
      "I0803 11:02:08.388808  3434 solver.cpp:314] Iteration 88, Testing net (#0)\n",
      "I0803 11:02:08.689045  3434 solver.cpp:363]     Test net output #0: accuracy = 0.203906\n",
      "I0803 11:02:08.689090  3434 solver.cpp:363]     Test net output #1: loss = 2.17427 (* 1 = 2.17427 loss)\n",
      "I0803 11:02:09.665403  3434 solver.cpp:217] Iteration 100, loss = 2.15096\n",
      "I0803 11:02:09.665441  3434 solver.cpp:234]     Train net output #0: loss = 2.15096 (* 1 = 2.15096 loss)\n",
      "I0803 11:02:09.713986  3434 solver.cpp:511] Iteration 100 (12.2045/s), lr = 0.0001\n",
      "I0803 11:02:15.634728  3434 solver.cpp:314] Iteration 176, Testing net (#0)\n",
      "I0803 11:02:15.934846  3434 solver.cpp:363]     Test net output #0: accuracy = 0.295312\n",
      "I0803 11:02:15.934882  3434 solver.cpp:363]     Test net output #1: loss = 1.97653 (* 1 = 1.97653 loss)\n",
      "I0803 11:02:17.859966  3434 solver.cpp:217] Iteration 200, loss = 1.91914\n",
      "I0803 11:02:17.860004  3434 solver.cpp:234]     Train net output #0: loss = 1.91914 (* 1 = 1.91914 loss)\n",
      "I0803 11:02:17.908648  3434 solver.cpp:511] Iteration 200 (12.2032/s), lr = 0.0001\n",
      "I0803 11:02:22.886893  3434 solver.cpp:314] Iteration 264, Testing net (#0)\n",
      "I0803 11:02:23.187512  3434 solver.cpp:363]     Test net output #0: accuracy = 0.321484\n",
      "I0803 11:02:23.187558  3434 solver.cpp:363]     Test net output #1: loss = 1.91004 (* 1 = 1.91004 loss)\n",
      "I0803 11:02:26.063267  3434 solver.cpp:217] Iteration 300, loss = 1.79197\n",
      "I0803 11:02:26.063304  3434 solver.cpp:234]     Train net output #0: loss = 1.79197 (* 1 = 1.79197 loss)\n",
      "I0803 11:02:26.111912  3434 solver.cpp:511] Iteration 300 (12.1904/s), lr = 0.0001\n",
      "I0803 11:02:30.141670  3434 solver.cpp:314] Iteration 352, Testing net (#0)\n",
      "I0803 11:02:30.441951  3434 solver.cpp:363]     Test net output #0: accuracy = 0.35\n",
      "I0803 11:02:30.441987  3434 solver.cpp:363]     Test net output #1: loss = 1.83849 (* 1 = 1.83849 loss)\n",
      "I0803 11:02:34.264652  3434 solver.cpp:217] Iteration 400, loss = 1.83513\n",
      "I0803 11:02:34.264765  3434 solver.cpp:234]     Train net output #0: loss = 1.83513 (* 1 = 1.83513 loss)\n",
      "I0803 11:02:34.313144  3434 solver.cpp:511] Iteration 400 (12.1934/s), lr = 0.0001\n",
      "I0803 11:02:37.398146  3434 solver.cpp:314] Iteration 440, Testing net (#0)\n",
      "I0803 11:02:37.700908  3434 solver.cpp:363]     Test net output #0: accuracy = 0.366211\n",
      "I0803 11:02:37.700947  3434 solver.cpp:363]     Test net output #1: loss = 1.79332 (* 1 = 1.79332 loss)\n",
      "I0803 11:02:42.475338  3434 solver.cpp:217] Iteration 500, loss = 1.85715\n",
      "I0803 11:02:42.475373  3434 solver.cpp:234]     Train net output #0: loss = 1.85715 (* 1 = 1.85715 loss)\n",
      "I0803 11:02:42.524057  3434 solver.cpp:511] Iteration 500 (12.179/s), lr = 0.0001\n",
      "I0803 11:02:44.657914  3434 solver.cpp:314] Iteration 528, Testing net (#0)\n",
      "I0803 11:02:44.959082  3434 solver.cpp:363]     Test net output #0: accuracy = 0.367383\n",
      "I0803 11:02:44.959116  3434 solver.cpp:363]     Test net output #1: loss = 1.7773 (* 1 = 1.7773 loss)\n",
      "I0803 11:02:50.683974  3434 solver.cpp:217] Iteration 600, loss = 1.70263\n",
      "I0803 11:02:50.684011  3434 solver.cpp:234]     Train net output #0: loss = 1.70263 (* 1 = 1.70263 loss)\n",
      "I0803 11:02:50.732666  3434 solver.cpp:511] Iteration 600 (12.1824/s), lr = 0.0001\n",
      "I0803 11:02:51.918021  3434 solver.cpp:314] Iteration 616, Testing net (#0)\n",
      "I0803 11:02:52.218808  3434 solver.cpp:363]     Test net output #0: accuracy = 0.404492\n",
      "I0803 11:02:52.218843  3434 solver.cpp:363]     Test net output #1: loss = 1.69943 (* 1 = 1.69943 loss)\n",
      "I0803 11:02:58.890552  3434 solver.cpp:217] Iteration 700, loss = 1.63326\n",
      "I0803 11:02:58.890596  3434 solver.cpp:234]     Train net output #0: loss = 1.63326 (* 1 = 1.63326 loss)\n",
      "I0803 11:02:58.939227  3434 solver.cpp:511] Iteration 700 (12.1855/s), lr = 0.0001\n",
      "I0803 11:02:59.176455  3434 solver.cpp:314] Iteration 704, Testing net (#0)\n",
      "I0803 11:02:59.477808  3434 solver.cpp:363]     Test net output #0: accuracy = 0.400586\n",
      "I0803 11:02:59.477885  3434 solver.cpp:363]     Test net output #1: loss = 1.69456 (* 1 = 1.69456 loss)\n",
      "I0803 11:03:06.433749  3434 solver.cpp:314] Iteration 792, Testing net (#0)\n",
      "I0803 11:03:06.734259  3434 solver.cpp:363]     Test net output #0: accuracy = 0.422656\n",
      "I0803 11:03:06.734311  3434 solver.cpp:363]     Test net output #1: loss = 1.64319 (* 1 = 1.64319 loss)\n",
      "I0803 11:03:07.397203  3434 solver.cpp:217] Iteration 800, loss = 1.68468\n",
      "I0803 11:03:07.397251  3434 solver.cpp:234]     Train net output #0: loss = 1.68468 (* 1 = 1.68468 loss)\n",
      "I0803 11:03:07.445902  3434 solver.cpp:511] Iteration 800 (11.7556/s), lr = 0.0001\n",
      "I0803 11:03:13.692675  3434 solver.cpp:314] Iteration 880, Testing net (#0)\n",
      "I0803 11:03:13.993813  3434 solver.cpp:363]     Test net output #0: accuracy = 0.399805\n",
      "I0803 11:03:13.993857  3434 solver.cpp:363]     Test net output #1: loss = 1.68981 (* 1 = 1.68981 loss)\n",
      "I0803 11:03:15.604254  3434 solver.cpp:217] Iteration 900, loss = 1.61974\n",
      "I0803 11:03:15.604293  3434 solver.cpp:234]     Train net output #0: loss = 1.61974 (* 1 = 1.61974 loss)\n",
      "I0803 11:03:15.653022  3434 solver.cpp:511] Iteration 900 (12.1846/s), lr = 1e-05\n",
      "I0803 11:03:20.951671  3434 solver.cpp:314] Iteration 968, Testing net (#0)\n",
      "I0803 11:03:21.251971  3434 solver.cpp:363]     Test net output #0: accuracy = 0.408203\n",
      "I0803 11:03:21.252007  3434 solver.cpp:363]     Test net output #1: loss = 1.65756 (* 1 = 1.65756 loss)\n",
      "I0803 11:03:23.813318  3434 solver.cpp:217] Iteration 1000, loss = 1.68538\n",
      "I0803 11:03:23.813355  3434 solver.cpp:234]     Train net output #0: loss = 1.68538 (* 1 = 1.68538 loss)\n",
      "I0803 11:03:23.862296  3434 solver.cpp:511] Iteration 1000 (12.1814/s), lr = 1e-05\n",
      "I0803 11:03:28.211098  3434 solver.cpp:314] Iteration 1056, Testing net (#0)\n",
      "I0803 11:03:28.511754  3434 solver.cpp:363]     Test net output #0: accuracy = 0.414453\n",
      "I0803 11:03:28.511790  3434 solver.cpp:363]     Test net output #1: loss = 1.64532 (* 1 = 1.64532 loss)\n",
      "I0803 11:03:32.021821  3434 solver.cpp:217] Iteration 1100, loss = 1.5474\n",
      "I0803 11:03:32.021869  3434 solver.cpp:234]     Train net output #0: loss = 1.5474 (* 1 = 1.5474 loss)\n",
      "I0803 11:03:32.070855  3434 solver.cpp:511] Iteration 1100 (12.1825/s), lr = 1e-05\n",
      "I0803 11:03:35.471032  3434 solver.cpp:314] Iteration 1144, Testing net (#0)\n",
      "I0803 11:03:35.772430  3434 solver.cpp:363]     Test net output #0: accuracy = 0.431836\n",
      "I0803 11:03:35.772475  3434 solver.cpp:363]     Test net output #1: loss = 1.62007 (* 1 = 1.62007 loss)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!/home/sandiego/Programas/caffe/build/tools/caffe train \\\n",
    "    --solver=/home/sandiego/septiembre/caffe/train_caffe/solver.prototxt \\\n",
    "    --gpu 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "# Entrenamiento con Digits\n",
    "\n",
    "#### Sesión interactiva\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Mejorar resultados de entrenamiento con Digits\n",
    "\n",
    "<img src=\"imagenes/beagle.jpg\">\n",
    "\n",
    "---\n",
    "\n",
    "##1. Primer intento\n",
    "\n",
    "<img src=\"imagenes/red1.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red1.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red1.png\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##2. Segundo intento\n",
    "\n",
    "<img src=\"imagenes/red2.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red2.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##3. Tercer Intento\n",
    "\n",
    "<img src=\"imagenes/red3.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red3.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##4. Cuarto Intento\n",
    "\n",
    "<img src=\"imagenes/red4.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red4.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##5. Quinto Intento\n",
    "\n",
    "<img src=\"imagenes/red5.png\">\n",
    "\n",
    "<img src=\"imagenes/stats_red5.png\" width=50% align=left>\n",
    "<img src=\"imagenes/predict_red5.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
